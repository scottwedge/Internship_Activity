{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Page Number :  5\n",
      "10  movies done in progress...\n",
      "20  movies done in progress...\n",
      "30  movies done in progress...\n",
      "40  movies done in progress...\n",
      "50  movies done in progress...\n",
      "60  movies done in progress...\n",
      "70  movies done in progress...\n",
      "80  movies done in progress...\n",
      "90  movies done in progress...\n",
      "100  movies done in progress...\n",
      "110  movies done in progress...\n",
      "120  movies done in progress...\n",
      "All Crawling Ended...\n",
      "Start Indexing New And Upcoming Data...\n",
      "All Crawling Ended...\n",
      "Spend Time :  1289.1455788612366\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 날짜 필터링 전 모든 데이터를 담는 곳\n",
    "\n",
    "soap2day_id_list_all = []\n",
    "title_list_all = []\n",
    "year_list_all = []\n",
    "time_list_all = []\n",
    "overview_list_all = []\n",
    "director_list_all = []\n",
    "starring_list_all = []\n",
    "url_list_all = []\n",
    "genre_list_all = []\n",
    "studio_list_all = []\n",
    "\n",
    "# 날짜 필터링 된 후 최신 데이터를 담는 곳\n",
    "\n",
    "soap2day_id_list = []\n",
    "title_list = []\n",
    "year_list = []\n",
    "time_list = []\n",
    "overview_list = []\n",
    "director_list = []\n",
    "starring_list = []\n",
    "url_list = []\n",
    "genre_list = []\n",
    "studio_list = []\n",
    "\n",
    "# 날짜 필터링 된 후 개봉예정 데이터를 담는 곳\n",
    "\n",
    "soap2day_id_list_2 = []\n",
    "title_list_2 = []\n",
    "year_list_2 = []\n",
    "time_list_2 = []\n",
    "overview_list_2 = []\n",
    "director_list_2 = []\n",
    "starring_list_2 = []\n",
    "url_list_2 = []\n",
    "genre_list_2 = []\n",
    "studio_list_2 = []\n",
    "\n",
    "\n",
    "# 날짜 필터링을 위한 리스트\n",
    "\n",
    "release_date_all = []\n",
    "\n",
    "# 시작\n",
    "\n",
    "path_ = '../../chromedriver/chromedriver'\n",
    "\n",
    "url = 'https://soap2day.to/movielist/sort/release/year/2020?page=1'\n",
    "\n",
    "driver = webdriver.Chrome(path_)\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(7)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "page_counter = []\n",
    "page_cnt = 1\n",
    "title_cnt = 1\n",
    "\n",
    "# 최대 페이지 넘버를 가져오기\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        page_num_finder = driver.find_element_by_xpath('/html/body/div/div[2]/div/div[2]/div/div[2]/div/div[2]/div[3]/ul/li[' + str(page_cnt + 2) + ']/a')\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    page_counter.append(page_num_finder.text)\n",
    "    page_cnt += 1\n",
    "    \n",
    "max_page = int(page_counter[-2])\n",
    "print('Last Page Number : ', max_page)\n",
    "\n",
    "# page 1부터 최대 페이지까지 모든 href를 가져오고, 그것을 주소 리스트에 삽입\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        title = driver.find_element_by_xpath('/html/body/div/div[2]/div/div[2]/div/div[2]/div/div[2]/div[1]/div/div[' + str(title_cnt) + ']/div/div[2]/h5/a')\n",
    "        title_list_all.append(title.text.strip())\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    url_list_all.append(title.get_attribute('href'))\n",
    "    title_cnt += 1\n",
    "\n",
    "for i in range(2, max_page + 1):\n",
    "    title_cnt = 1\n",
    "    url = 'https://soap2day.to/movielist/sort/release/year/2020?page=' + str(i)\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            title = driver.find_element_by_xpath('/html/body/div/div[2]/div/div[2]/div/div[2]/div/div[2]/div[1]/div/div[' + str(title_cnt) + ']/div/div[2]/h5/a')\n",
    "            title_list_all.append(title.text.strip())\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "        url_list_all.append(title.get_attribute('href'))\n",
    "        title_cnt += 1\n",
    "\n",
    "crawling_counter = 0\n",
    "        \n",
    "for i in url_list_all:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    crawling_counter += 1\n",
    "    \n",
    "    \n",
    "    # 영화 고유 id값\n",
    "    \n",
    "    id_loc_1 = i.find('movie')\n",
    "    id_loc_2 = i.find('html')\n",
    "    \n",
    "    soap2day_id_list_all.append(i[id_loc_1 + 6:id_loc_2 - 1])\n",
    "    \n",
    "    # 감독\n",
    "    \n",
    "    temp_director = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div/div[3]/div[1]/div/div/div/div[1]/p[3]')\n",
    "    director_list_all.append(temp_director.text.strip())\n",
    "    \n",
    "    # 출연 배우\n",
    "    \n",
    "    temp_starring = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div/div[3]/div[1]/div/div/div/div[1]/p[6]')\n",
    "    starring_list_all.append(temp_starring.text.strip())\n",
    "    \n",
    "    # 장르\n",
    "    \n",
    "    temp_genre = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div/div[3]/div[1]/div/div/div/div[1]/p[9]')\n",
    "    genre_list_all.append(temp_genre.text.strip())\n",
    "    \n",
    "    # 출시년도, indexing을 위한 출시일 년,월,일로 슬라이싱\n",
    "    \n",
    "    temp_release = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div/div[3]/div[1]/div/div/div/div[1]/p[12]')\n",
    "    release_tmp = temp_release.text.strip()\n",
    "    try:\n",
    "        release_tmp_year = int(release_tmp[:4])\n",
    "        release_tmp_month = int(release_tmp[5:7])\n",
    "        release_tmp_day = int(release_tmp[8:])\n",
    "    except ValueError:\n",
    "        year_list_all.append('None')\n",
    "        release_date_all.append('None')\n",
    "    else:\n",
    "        year_list_all.append(release_tmp_year)\n",
    "        release_date_all.append(date(release_tmp_year, release_tmp_month, release_tmp_day))\n",
    "    \n",
    "    # 개요\n",
    "    \n",
    "    temp_overview = driver.find_element_by_xpath('//*[@id=\"wrap\"]')\n",
    "    overview_list_all.append(temp_overview.text.strip())\n",
    "    \n",
    "    if crawling_counter % 10 == 0:\n",
    "        print(str(crawling_counter), ' movies done in progress...')\n",
    "    \n",
    "print('All Crawling Ended...')\n",
    "\n",
    "print('Start Indexing New And Upcoming Data...')\n",
    "\n",
    "recent_index = []\n",
    "upcoming_index = []\n",
    "\n",
    "# indexing\n",
    "\n",
    "for i in range(len(release_date_all)):\n",
    "    if release_date_all[i] != 'None':\n",
    "        if (release_date_all[i] > date.today() - timedelta(days = 60)) and (release_date_all[i] < date.today() + timedelta(days = 7)):\n",
    "            recent_index.append(i)\n",
    "        elif (release_date_all[i] >= date.today() + timedelta(days = 7)):\n",
    "            upcoming_index.append(i)\n",
    "        \n",
    "# 최신 영화 기준에 맞는 것들 삽입        \n",
    "        \n",
    "for i in recent_index:\n",
    "    soap2day_id_list.append(soap2day_id_list_all[i])\n",
    "    title_list.append(title_list_all[i])\n",
    "    year_list.append(year_list_all[i])\n",
    "    overview_list.append(overview_list_all[i])\n",
    "    director_list.append(director_list_all[i])\n",
    "    starring_list.append(starring_list_all[i])\n",
    "    url_list.append(url_list_all[i])\n",
    "    genre_list.append(genre_list_all[i])\n",
    "    \n",
    "# 개봉 예정 영화 기준에 맞는 것들 삽입\n",
    "\n",
    "for i in upcoming_index:\n",
    "    soap2day_id_list_2.append(soap2day_id_list_all[i])\n",
    "    title_list_2.append(title_list_all[i])\n",
    "    year_list_2.append(year_list_all[i])\n",
    "    overview_list_2.append(overview_list_all[i])\n",
    "    director_list_2.append(director_list_all[i])\n",
    "    starring_list_2.append(starring_list_all[i])\n",
    "    url_list_2.append(url_list_all[i])\n",
    "    genre_list_2.append(genre_list_all[i])\n",
    "    \n",
    "print('All Crawling Ended...')\n",
    "\n",
    "\n",
    "items_recent = pd.DataFrame({'soap2day_id' : soap2day_id_list, 'title' : title_list, 'release' : year_list, \n",
    "                      'genres' : genre_list, 'director' : director_list, 'actor' : starring_list,\n",
    "                      'country' : np.nan, 'runtime' : np.nan, 'production' : np.nan, 'overview' : overview_list,\n",
    "                      'url' : url_list})\n",
    "\n",
    "items_upcoming = pd.DataFrame({'soap2day_id' : soap2day_id_list_2, 'title' : title_list_2, 'release' : year_list_2, \n",
    "                      'genres' : genre_list_2, 'director' : director_list_2, 'actor' : starring_list_2,\n",
    "                      'country' : np.nan, 'runtime' : np.nan, 'production' : np.nan, 'overview' : overview_list_2,\n",
    "                      'url' : url_list_2})\n",
    "\n",
    "items_recent.to_excel('SOAP2DAY_Crawling_Recent.xlsx')\n",
    "items_upcoming.to_excel('SOAP2DAY_Crawling_Upcoming.xlsx')\n",
    "\n",
    "\n",
    "print('Spend Time : ', time.time() - start_time)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
